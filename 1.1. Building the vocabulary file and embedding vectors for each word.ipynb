{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start parsing abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting text from xml files\n",
    "from xml.dom import minidom\n",
    "\n",
    "xmldoc = minidom.parse('1.1.text.xml')\n",
    "def getTokens(node):\n",
    "    tokens = []\n",
    "    if node is not None:\n",
    "        if node.nodeType == node.TEXT_NODE:\n",
    "            tokens.extend(node.data.split())\n",
    "        elif node.nodeType == node.ELEMENT_NODE:\n",
    "            for sub_array in [item.data.split() for item in node.childNodes]:\n",
    "                tokens.extend(sub_array)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5259"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting all enities \n",
    "all_entities = []\n",
    "for entity in xmldoc.getElementsByTagName('entity'):\n",
    "    entityWords = getTokens(entity)\n",
    "    all_entities.append(entityWords)\n",
    "\n",
    "#print(all_entities)\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geTitle(nodelist):\n",
    "    titles = []\n",
    "    for node in nodelist:\n",
    "        if node.nodeType == node.TEXT_NODE:\n",
    "            titles.append(node.data)\n",
    "    return ''.join(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all titles. \n",
    "all_titles = []\n",
    "for title in xmldoc.getElementsByTagName('title'):\n",
    "    title_text = geTitle(title.childNodes)\n",
    "    all_titles.append(title_text.lower())\n",
    "#print(all_titles)  \n",
    "len(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAbstractText(abstractNode):\n",
    "    # Extract abstract text\n",
    "    abstractElements = []\n",
    "    for item in abstractNode.childNodes:\n",
    "        # If plain text node\n",
    "        if item.nodeType == item.TEXT_NODE:\n",
    "            abstractElements.append(item.data)\n",
    "        # If xml tag node\n",
    "        elif item.nodeType == item.ELEMENT_NODE:\n",
    "            for sub_array in [sub_item.data for sub_item in item.childNodes]:\n",
    "                abstractElements.append(sub_array)\n",
    "    return ''.join(abstractElements)\n",
    "\n",
    "\n",
    "all_abstracts = []\n",
    "for abstract in xmldoc.getElementsByTagName('abstract'):\n",
    "    abstractText = getAbstractText(abstract)\n",
    "    all_abstracts.append(abstractText)\n",
    "\n",
    "#print(all_abstracts)\n",
    "len(all_abstracts)\n",
    "type(all_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity detection for information access to oral communication\n"
     ]
    }
   ],
   "source": [
    "#350 titles + 350 abstracts\n",
    "all_data = all_titles + all_abstracts\n",
    "\n",
    "print(all_data[0])\n",
    "#len(all_data)\n",
    "#type(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43385"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize text\n",
    "tokens = [word_tokenize(i) for i in all_data]\n",
    "tokens = list(itertools.chain.from_iterable(tokens))\n",
    "\n",
    "#print(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but', 'apt', 'reported', 'lexsys', 'groups', 'slavonic', 'marcus', 'lemma-', 'clustering', 'bootstrap', 'valuable', 'preferred', 'unordered', \"'95\", 'cf', 'bio-medical', 'weaknesses', 'abductive', 'walked', 'pairing', 'respectful', 'pos', 'date', 'facilitates', 'firmly', 'sentence-', 'demonstrations', 'filter', 'principle', 'p', 'convert', 'body', 'weighted', 'imitation', 'erroneous', 'imposed', '-based', 'memorize', 'l', 'tractability', 'reduplication', 'connectives', 'infomagnets', 'functional', 'powerful', 'communities', 'independence', 'data', 'spontaneous', 'counts', 'unix', 'inapplicable', 'educational', 'ambiguity', 'practice', 'resultant', 'anchoring', 'theoretical', 'compression', 'indeed', 'retrieves', 'particularly', 'corrector', 'syntactic', 'approaches', 'modifier', 'correlations', 'try', 'downstream', 'spatial', 'array-based', 'decrease', 'topical', 'heads', 'quality', 'category', 'french-dutch', 'practically', 'gen', 'salient', 'error', 'interfaces', 'converse', 'software', 'items', 'concept-based', 'nigam', 'index', 'turn', 'semantically', 'render', 'concept-', 'dominates', 'lyric', 'development', 'fragment', 'interpretations', 'scanned', 'constrained', 'duplicating', 'fixed', 'gaussian', 'qualitative', 'therefore', 'easy-to-implement', 'draw', 'scoring', 'state', 'tells', 'spelling', 'satisfying', 'listener', 'pioneered', 'links', 'computers', 'lie', 'tiers', 'gui', '|g||w|3-e', 'genuinely', 'uncover', 'aspect', 'elaborated', 'break', 'h.', 'zernik88', 'maximal', 'technology', 'collaborations', 'derived', 'motivates', 'ensures', 'sentence-plan-ranker', 'stack', 'principles', 'obtained', 'knowledge-based', 'scanned-document', 'successive', 'improvements', 'besides', 'mechanism', 'take', 'principle-and-parameters', 'combines', 'explored', 'well-formedness', 'capability', 'referents', 'underlies', 'hmm', '1983', 'mimo', 'optimum', 'corrected', 'coalition', 'may', 'declarative', 'rhetorical', 'closed', 'parsing-based', 'benefits', 'parseable', 'reduces', 'form-oriented', '70', 'women', 'push', 'parts', 'ends', 'above', 'laws', 'bakeoff', 'build', 'semcor', 'baseline', 'telecom', 'air', 'site', 'flexibilities', 'reliably', 'you', 'hk', 'infrastructure', 'motivate', 'equivalent', 'disjunctive', 'utilize', 'triplets', 'human', '87', 'boosting', 'recomposed', 'enough', 'cooperatively', 'inventories', 'change', 'acl', 'optimization', 'script', 'wwer', 'conventionally', 'rely', 'which', 'foundation', 'step', 'nlg', 'topmost', 'human-machine', 'carrying', 'dictionary-based', 'dependency', 'word-lemma', \"'91\", 'histogram', 'categorization', 'monotonically', 'interchangeable', 'many', 'organizations', '1.', 'mapping', 'supply', 'alignment', 'wordnets', 'covers', 'loglinear', 'epistemological', 'space', 'exchange', 'vme', 'synthesize', 'quot', 'zoological', 'decision', 'ordering', 'update', 'cost', 'reyle', 'outlines', 'fragmentary', 'ill-formed', 'corpora', \"'new\", 'simultaneous-distributive', 'iteration', 'partly', 'defeasibility', 'suggests', 'systematic', 'inherent', 'simtran', 'establishing', 'lyric-based', 'conceptualizes', 'moderate', 'conveying', 'visible', 'moreover', 'assess', 'positve', 'generalized', 'operations', 'passage', 'logic', 'per', 'fine-tuning', 'ubiquitous', 'purpose', 'procedure', 'finding', 'how', 'arguments', 'shortcomings', 'tutoring', 'numerous', 'anaphoric', 'senseval2', 'constructions', 'antecedent', 'expressive', 'arabic', 'lend', 'lf', 'occur', 'multi-site', 'demonstrator', 'aim', 'offering', '11', 'slightly', 'e.g.', 'merely', 'subtopic', 'offer', 'no', 'constraints', 'hand-crafting', 'student', 'frequent', 'inverses', 'combinatorial', 'mrr', 'log-linear', 'small-scale', 'cognitive', 'settings', 'programmable', \"'=\", 'entity-based', 'processing', 'kamp', 'situation', 'knight', 'syntactical', 'paths', 'ii', 'workshop', 'potential', 'modal', 'i/l', 'employed', 'total', 'muc-6', 'lms', 'discontinuous', 'defeat', 'predicative', 'industry', 'orientation', 'symbols', 'bibliographic', 'followed', 'birds', 'non-monotonic', 'similarly', 'walks', 'computation', 'crossing', 'store', 'muc-4', 'feature-rich', 'incorporation', 'goes', '23,000', 'maximize', 'gb', 'transliteration', 'distinctions', 'engine', 'identifiable', 'decoders', 'stories', 'clues', 'machine', 'bound', 'orthographical', 'operates', 'editing', 'dialog', 'tl', 'contexts', 'etc', 'gene', 'structured', 'dropped', '60', 'localized', 'explicitation', 'bus', 'representations', 'runs', 'output', 'rejoinders', 'spanish', 'monolingual', 'foreign', 'criteria', 'inter-related', 'planning', 'generators', 'speech/language', 'two', 'figure', 'metagrammatical', 'france', 'point', 'insured', 'node', 'improve', 'bottom-up', 'multi-lingual', 'algorithmic', 'rough', 'walk', 'disk', '90', 'adopting', 'validity', 'capitalization', 'initiated', 'none', 'paraphrases', 'hand-produced', 'suite', 'consultation', '0', 'coverage', 'mixtures', 'summaries', 'prague', 'objectives', 'object', 'guided', 'judgment', 'interesting', 'resulting', 'adequacy', 'last', 'solutions', 'recommended', '1991b', 'interlocutor', 'example-based', 'exploited', 'affinity', 'necessary', 'expressiveness', 'parser/generator', 'agglutinating', 'well-known', 'ideograms', 'guesses', 'lost', 'explication', 'separated', 'informed', 'signature', 'independency', 'behavior', 'parametric', 'gap', 'nitpicking', 'surprisingly', 'represent', 'nps', 'generation', 'pivot', 'lexicalized', 'over', 'collaborative', '97,5', 'inuktitut', 'discourse-relevant', 'trajectory', 'n-best', 'implausible', 'classification', 'implementing', 'bayesian', 'impersonal', 'extensions', 'extend', 'cognition', 'polarity-tagged', 'obviating', 'truth-conditions', 'minimalist', 'strongly', 'estimations', 'morphology', 'co-workers', 'dominance', 'consequences', 'ranked', 'in-degree', 'hk-open', 'sls', 'temple', 'continuing', 'notify', 'mediated', 'creating', 'request', 'document', 'schemata', 'amorph', 'often', 'traditionally', 'form', 'nonverbal', 'presence', 'rank', 'stem', 'processes', 'recognition', 'identifying', 'wish', 'answer/question', 'turkish', 'gaze', 'examined', 'affix', 'verbmobil', 'interact', 'manager', 'maximization', '#', 'undesirable', 'efficient', 'comparator', 'pick', 'passives', 'assured', 'kds', 'had', 'matrix', 'np-', 'train', 'weighting', 'lsa-based', 'beliefs', 'severe', '155', 'meronymy', 'trost', 'typical', 'applicable', 'transforming', 'segment-based', 'stop', 'addressed', 'framework', 'copying', 'msr-close', 'transliterated', 'metaphor', 'combined', 'records', 'context-free', 'kl-conc', 'aspectual', 'metrics', 'partners', 'summarisation', 'portable', 'resolved', 'verb-noun', 'wh-movement', 'backgrounds', 'stylistic', 'practical', 'n-grams', 'l0', 'formatting', 'interpreting', 'distance', 'construct', 'computations', 'interlingual', 'argumentation', 'latter', 'approach.keywords', 'high-accuracy', 'matched', 'n6', 'core', 'derive', 'polymorphemic', 'become', 'carl', \"'synchronous\", 'treatmemt', 'exact', 'learns', 'formed', 'whose', 'discourse-level', 'non-terminals', 'browsers', 'explanatory', 'word-distance', 'gender', 'up', 'neal', 'binding', 'categories', 'commercial', 'lexicon', 'korean-to-english', 'indicate', 'author', '12,000', 'pds', 'respects', 'individual', 'delimiters', 'tight-coupling', 'proposals', 'antonymy', 'likelihood', 'substitution', 'max-ent', 'handle', 'edol', 'spr', 'sketched', 'nuclearity', 'tools', 'going', 'layout', 'inheritance', 'forecasting', 'etc.', 'collecting', 'dod', 'bracketed', 'database', 'hubs', 'initiative', 'kernel-based', 'makes', 'psychological', 'scheme', 'controlling', 'tipster', 'frameworks', 'deconverters', 'overall', 'xtag', 'claimed', 'rich', 'heuristic', 'constructs', 'putting', 'plays', 'physiology', 'graphs', 'mining', 'langauge', 'fill', 'cer', 'interleaved', '10.4m', '4', 'iv', 'tracks', 'mostly', 'ambiguous', 'log', 'shieber', 'history', 'engaging', 'outperform', 'existed', 'propose', '360k', 'indicated', 'resource', 'introduce', 'inflow', 'perfect', 'state-of-the', 'heuristics', 'allowing', 'contemporary', 'fashion', 'highlights', 'surveys', 'bit-vector', 'structure', 'place', 'multimodal', 'modes', 'relating', 'deadline', 'supports', 'harmony', 'patr-ii', 'assistant', 'calculated', 're-estimate', 'to', 'naturally', 'successes', 'topics', 'f-structures', 'imported', 'ten', 'hmms', 'marines', 'sentence', 'stops', 'since', 'addition', 'triggers', 'subgraphs', 'link', 'english-spanish', 'graph-search', 'patterns', 'adverbial', 'sharing', 'pattern', 'analyzer', 'characterization', 'swart', 'identify', 'principled', 'on', 'stricto', 'efficiently', 'x', 'native', 'encoded', 'shinmeikai', 'psi-klone', '*', 'arise', 'cognito-pragmatic', 'princeton', 'right', 'emphasizes', 'revisit', 'negra', '49.3', 'exercises', 'three', 'faced', 'xml', 'reasonably', 'matching', 'still', 'exhibit', 'balkanet', 'correlation', 'focusing', 'match', 'compositionality', 'jointly', 'from', 'annotating', 'highly', 'ordered', 'rating', 'beings', 'techniques', 'statistical', 'reranking', 'unadulterated', 'text-plan', 'considerations', 'decoding', 'labels', 'substitutions', 'mit', 'intractable', 'desirable', 'choice', 'english-estonian', 'pattern-matching', 'workshops', 'outstanding', 'miscommunication', 'reconceptualize', 'provide', 'text.kds', 'multi-strategy', 'ontology', 'power', 'web-based', 'chomsky', 'themes', '85', 'splitting', 'challenging', 'collocational', 'definite', 'dependencies', 'labelled', 'correspondences', 'suggested', 'correctly', 'non-configurational', 'hastiness', 'responsible', 'transfers', 'permissible', 'search', '18.3m', 'flow', 'top', \"''\", 'classified', 'logical', 'role', 'devoted', 'enriching', 'texts', 'taken', 'alignments', 'position', 'si', 'examination', 'california', 'graph', 'senses', 'twenty', 'changed', 'device', 'considerably', 'trying', 'applying', 'state-of-the-art', 'share', 'dual', 'specifically', '100-fold', 'capture', 'stall', 'achieves', 'translingual', 'bitexts', 'note', 'scenario', 'taking', 'permutation', 'within', 'included', 'sort', 'caseframe', 'refer', 'loss', 'respect', 'substring', 'ntu-approach', 'i860', 'hdags', 'model', 'enlarging', 'diverse', 'demonstrated', 'patchy', 'linguistically-grounded', 'precise', 'complementation', '2.0', '4.1', 'lexically-induced', 'terabyte', 'nods', 'modeling', 're-utterance', 'mirrors', 'memory', 'et', 'variable', 'provides', 'year', 'tokens', 'significant', 'passive', 'derivations', 'triphone', 'occurrence', 'terminology', 'sets', 'one-to-one', 'binary', 'facilitate', 'witnessed', 'algorithm', 'dark', 'bring', '10', 'approximately', 'reports', 'combiner', 'tap-xl', 'ones', 'preparatory', 'exploit', 'challenge', 'mdcc', 'large', 'stored', 'sentence-boundary-crossing', 'organized', 'course', 'seed', 'effectiveness', 'tailored', 'syllogistic', 'acquires', 'implementation', 'muc', 'operable', 'suffixes', 'productive', 'prevention', 'performs', 'abstracting', 'standalone', 'readings', 'dubious', 'discovers', 'hypothesize', 'behind', 'periods', 'value', 'named', 'inputs', 'ascent', 'distributional', 'names', 'errors', 'margin', 'ensure', 'coocurrence', 'commonality', 'longman', 'confer', 'equivalence', 'cdd', 'rephrase', 'novel', 'summarized', 'judgments', 'katakana', 'world', 'source', 'test-score', 'karttunen', 'principle-based', 'kinds', 'measure', 'japanese-to-english', 'w', 'consisting', 'considering', '73.2', 'accepts', 'workability', 'ineffective', 'higher', 'pronouns', 'paraphrasing', 'transparent', 'versions', 'multi-event', 'ever', 'marks', 'scratch', 'counted', 'short', 'forest', 'their', 'agent-based', 'as', 'subparagraph', 'meaningful', 'size', 'cooccurrence-based', 'involving', '2004', 'lexical-syntactic', 'orthographic', 'of-', 'english-bulgarian', 'interlingua', 'incorporates', 'gives', 'attempts', 'compounds', 'referred', 'newsgroup', 'overt', 'gold-standard', 'sub-categorization', 'imposing', 'foot', 'representative', 'vocabulary', 'signal-based', 'toponyms', 'summarize', 'describes', 'learning', 'meaning', 'sub-lexical', 'trick', 'decomposing', 'undergone', 'weighed', 'lilt', 'intention', 'either', 'he/she/man/woman', 'changeable', 'straightforward', 'verbs', 'well-defined', 'listen-communicate-show', 'multiparty', 'remains', 'ratings', 'document-oriented', 'czech', 'faq-like', 'think', 'mathematical', 'metarules', '40', 'progressing', 'conceptually', 'markup', 'five', 'reconstruct', 'estimates', 'naming', 'forests', 'commentary', 'acoustic', 'n', 'segmenter', 'nca', 'johnston', 'consuming', 'eigenvectors', 'lucy', 'thought', 'inherently', 'low', 'computational', 'translated', 'rather', 'out-of-domain', 'broad', 'progresses', 'findings', 'tunable', 'forecaster', 'cky-style', 'successful', 'drive', 'fulfillment', '-96.7', 'ot', 'reliable', 'similarities', 'converting', 'reasoning', 'sensitivity', 'extensional', 'unique', 'wide', 'emphasize', 'discharge', 'ptq', 'facility', 'ai', 'able', '``', 'rohrer', 'log-likelihood', 'non-native', 'contextual', 'grammar', 'fuzzy', 'cost-efficiency', 'formatted', 'specialized', 'nl', 'preceeding', 'paraphrase', 'spatially', 'captures', '2007', 'lists', 'ideal', 'finished', 'compare', 'usability', 'recognize', 'weather', 'expression', 'entity-oriented', 'disregarded', 'breaking-off', 'credibility', 'organize', 'propbank', 'free-content', 'assessing', 'normf', 'back-off', 'feasibility', 'non-contiguous', 'treatments', 'supplemented', 'claims', 'average', 'indicators', '77', 'cope', 'halliday', 'drawing', 'current', 'requestors', 'aided', 'lexical-cohesion', 'elementary', \"'92\", 'unfolds', 'reestimation', 'propositions', 'discover', 'meanings', 'attending', 'help', 'inheritance-based', 'hardness', 'people', 'gathering', 'alleviate', 'elements', 'tended', 'meet', 'chosen', 'knowledgebases', 'fraction', 'session', 'protocols', 'proposed', 'tm', 'question-answering', 'auxiliary', 'hierarchically-structured', 'exactly', 'scarcely', 'separately', 'medical', 'serve', 'merging', 'coarse-level', 'families', 'unsupervised', 'early', 'premature', 'unlabeled', 'formulate', 'optimizing', 'called', 'sole', 'modification', 'fda', 'enabled', 'transliterations', 'decide', 'automatic', 'stream', 'notions', 'multiply', 'message', 'show', 'reproducability', 'darpa', 'completely', 'types', 'differed', '97.9', 'intensional', 'analysed', 'unregistered', 'tree-to-tree', 'sentence-plan-generator', 'dynamic', 'english-hungarian', 'packing', 'model-theoretic', 'transducer', 'transitional', 'locality', 'are', 'oral', 'reuse', 'formally', 'observing', 'exceptions', 'fake', 'context-freeness', 'well', 'problematic', 'a', 'word-trie', 'unexplained', 'datasets', 'arabic-english', 'navy', 'sampling', 'happen', 'unstructured', 'spot', 'checking', 'dutch', 'connection', 'direction-giving', 'aware', 'classical', 'unit', 'conflicts', 'end', 'intervals', 'directed', 'intelligent', 'particular', 'iterations', 'streams', 'need', 'fragments', 'qa', 'motivation', 'validation', '447', 'generative', 'preserve', 'routing', 'occurrences', 'descent', 'longitudinal', 'email', 'assignments', 'corpus', 'completion', 'explanation', 'passed', 'millions', 'spoken-language', 'fsas', 'implemented', 'capacity', 'mdl', 'enumeration', 'contrary', 'marker', 'tea', 'starting', 'attune', 'probabilistic', 'msr-open', 'integrating', 'frequencies', 'generating', 'factored', 'forcing', 'allowed', 'copies', '1994', 'explicit', 'viewed', 'udrs', 'real', 'nested', 'moment', 'block', 'generalize', 'positive', 'civilian', 'tease', 'inflectional', 'smt', 'gained', '75', 'pk-closed', 'seemed', 'reranker', 'interconnected', 'merge', '1996', 'amounts', 'announce', 'lsp-mlp', '100,000', 'ported', 'outputs', 'sentences', 'extraposition', 'interrelated', 'gpsg', 'decision-tree', 'approximating', 'blocks', 'baselines', 'ellison', 'indexation', 'boost', 'extensively', 'assumed', 'silva', '1987', 'repeat', 'collections', 'carry', 'exponential', 'never', '113k', '2.284', 'overlap', 'learnt', 'bayes-risk', 'concerning', 'single-snippet', 'speeches', 'interactions', 'interrogatives', 'suffix', 'rate', 'item', 'few', 'communication', 'lattices', 'predicate', 'triplet-based', 'timbl', 'satisfies', 'actually', 'variations', 'unigram', 'authoring', 'caption', 'papers', 'two-step', 'mixture', 'induced', 'indirectly', '30', 'unambiguous', 'expanding', 'em-algorithm', 'absence', 'chart', 'interword', 'results', 'carefully', '000', 'formalization', '10k', 'known', 'been', 'simulation', 'real-valued', 'replaced', 'non-matches', 'spoken', 'line', 'organizational', 'run', 'dialogues', 'classes', 'single-tree', 'policy', 'troponymic', 'pipelined', 'next', 'observations', 'research', 'inaccurate', 'transliteration/back-transliteration', '0.4090', 'transition', 'summit', 'kl-one', 'rcl', 'account', 'begins', 'examines', 'file', 'we', 'integral', 'supertagging', 'driven', 'experimentally', 'meaning-entailing', 'graphics', 'authoritative', 'design', 'sentiment', 'gale', 'morpho-syntactic', 'informational', 'aggregate', 'guarantee', 'four', 'ordinary', 'parse', 'disjoint', 'defined', 'schutze', 'min', 'depends', 'verifies', 'sides', 'concerns', 'corresponds', 'entropy', 'vital', 'hold', 'resolving', 'synonymous', 'benefit', 'dynamic-programming', 'restricted-domain', 'non-local', 'right-side', 'separating', 'english-to-japanese', 'embodied', 'background', 'expanded', 'judges', 'combination', 'met', 'arc', 'nearest', 'scarce', 'citations', 'features', 'newly', 'l0-unl', 'without', 'overview', 'ties', 'metaphors', 'decided', 'grasp', 'encouraging', 'base', 'speech-search', 'direction', 'entropy-based', 'accommodating', 'generate', 'constraining', 'degrade', 'cited', 'utilized', 'mobile', 'uses', 'limit', 'takes', '12.5', 'dispositions', 'senseval-2', 'abstractions', 'worked', 'syllogism', 'examples', 'subset', 'several', 'macro', 'multisentential', 'vast', 'tagged', 'example-base', 'sansei-do', 'entry', 'fail', 'young', 'lemmatization', 'activity', 'behaviour', 'answers', 'reliability', 'archive', 'containing', 'class-oriented', 'closely', 'tightly', 'worst-case', 'rates', 'adaptive', 'bigram', 'tonnes', 'critical', 'ingredients', 'major', 'mode', 'beam-search', 'signals', 'get', 'flat', 'off-the-shelf', 'word-dependent', 'sources', 'locations', 'formalizing', 'description', '12', 'simple', 'paradigm', 'even', 'ideally', 'arbitrary', 'establish', 'decision-making', 'recently', 'cases', 'analyst', 'thai', 'wrong', 'move', 'nugget', 'comprehensive', '3', 'issue', '1988', 'coping', 'relate', 'seeks', 'unknown', 'prominence', 'then', 'defeasible', 'dependence', 'grammatical', 'non-terminal', 'lcs-based', 'evaluated', 'derivation', 'projects', 'missiles', 'ana', 'adaptable', 'partee', 'summations', 'entities', '0.889', '6', 'pc', 'noun', 'ner', 'necessarily', 'uniform', 'preprocessing', 'viewpoint', 'adopted', 'focus', 'hidden', 'ontoscore', 'evidence', 'necessity', 'contributed', 'novice', 'measuring', '6.56', 'inter-annotator', 'kyoto', 'penn', 'meta-inference', 'arbitrarily', '-hyponym', 'alternative', 'doubt', 'lo-english', 'b', 'loose', 'ibm', 'neighbour', 'interlingua-based', 'wordnet-based', 'encourages', 'paktus', 'execution', 'apply', 'heavy-hearted', 'components', 'operate', 'tabular', 'runtime', 'find', 'dependent', 'references', 'arabia', 'widely', 'miscommunications', 'huge', 'parallel', 'addresses', 'analyzing', 'shows', 'aids', 'q', 'relatively', 'partial', 'approximations', 'also', 'slice', 'hk-closed', 'treat', 'impacts', 'shifts', 'contributions', 'elsewhere', 'bmm', 'sr', 'differentiate', 'consists', '14', 'analyses', 'apparent', 'approximate', 'assessment', 'studies', 'resemble', 'lemmatize', 'satisfaction', 'our', 'morphological', 'clusters', 'empirical', 'markers', 'conditioning', 'parses', '<', 'ignored', 'agenda-based', 'scene', 'expectation-maximization', 'comprising', 'given', 'refinement', 'street', 'chunks', 'user-study', 'quasi-destructive', 'e.', 'go', 'modify', 'between', 'botanical', 'stabler', 'culture-', 'ways', 'optimal', 'all', 'prolog', 'commitments', 'inducing', 'conventions', 'stand', 'tuned', 'multi-field', 'generally', 'domain-specific', 'accuracies', 'kanji', 'linear', 'translations', 'time-complexity', 'refuted', 'your', 'extent', 'focusses', 'ontologies', 'estimate', 'dedicated', 'cooperative', 'bolstered', 'happens', 'actual', 'plausible', 'progress', 'utterance', 'act', 'submanifold', 'align', 'nevertheless', 'predominant', 'due', 'sufficiently', 'needed', 'instantiation', 'relationship', 'fairly', 'distortion', 'explicitly', 'points', 'presents', 'broad-coverage', 'configuration', 'indifference', 'stemmer', 'functionality', 'bia', 'compatible', 'improves', 'guidance', 'third', 'well-motivated', 'effects', 'adverbials', 'refinements', 'scaling', 'put', 'consistently', 'enhances', 'entire', 'freund', 'leaving', 'add', 'hand-built', 'visualizing', 'generic', 'subtypes', 'general-purpose', 'context-dependent', 'tied-mixture', 'satisfy', 'normal', 'analysis', 'newswire', 'four-participants', 'robust', 'imperfect', 'produced', 'manually', 'presume', 'submitted', 'calibrated', 'influence', 'translating', 'rcgs', 'parsed', 'transcription', 'abstracts', 'hardware', 'antecedents', 'lr-parser', 'specified', 'way', 'attack', 'frequently', 'adequate', 'cross-serial', 'generator', 'parsing-as-deduction', 'about', 'japan', 'tolerance', 'wire', 'approx', 'help-desk', 'better', 'generalizations', 'upper', 'question-', 'looking', 'literal', 'inspired', 'limits', 'translator', 'domains', 'reached', 'question-answer', 'error-correction', 'again', 'title', '2003', 'advantage', 'problem', 'passing', 'characteristics', 'theme', \"'\", 'analytical', '1.6', 'generalization', 'condition', 'ramshaw', 'left-side', 'faster', 'idiosyncracies', 'coordination', 'details', 'context', 'reflected', 'summarizes', 'american', 'extra-grammatical', 'meteorological', 'conrath', 'found', 'html', 'separation', 'referring', 'data-driven', 'konpyuutaa', 'content', 'uncertainty', 'icall', 'infeasible', 'familiarity', 'offers', 'toy', 'involved', 'focused', 'overcomes', 'biber,1993', 'coupled', 'rendered', 'wsi', 'transformations', 'vagueness', 'combinatorics', 'trans-context-free', 'deal', 'treatment', 'long', 'thai-english', 'word', 'consider', 'easily', 'ultimately', 'decorated', 'adjacent', 'have', 'liaisons', 'laboratory', 'hoc', 'fared', 'documentation', 'wh-questions', 'hpsg', 'senseval-3', 'samples', 'speculative', '110,000', 'corner', 'members', 'proportions', 'restrictive', 'child', 'gain', 'jintaccs', 'compactness', 'specification', 'childes', 'mixed-initiative', 'u.s.', 'designing', 'korean', 'praguian', 'hyponymy', 'plume', 'roberts', 'coordinate', 'opposition', 'fluctuation', 'alternatives', 'facile', 'confidence', 'laugh', 'transform', 'flexibility', 'relation', 'finite', 'markov', 'nltoolset', 'previous', 'art', 'arguello', 'assessors', 'default', 'contribute', 'best', 'lexicons', 'srhs', 'communicate', 'illustrating', 'phrasal', 'works', 'achieved', 'predicted', 'projection', 'aligned', 'parallelise', 'extract', 'composition', 'primitive', 'suppress', 'perform', 'tagger', 'around', 'estimation', 'reach', 'lm', 'routine', 'averaging', 'raises', 'purely', 'russian', 'integrate', 'synchronous', 'animation', 'quantification', 'presuppositional', 'detect', 'interactive', 'little', 'card', 'skilled', 'internal', 'neutral', 'bottlenecks', 'label', 'good-quality', 'probably', 'limitation', 'icicle', 'give', 'polysemic', 'interaction', 'bref', 'experiments', 'cover', '87.6', 'browser', 'typicality', 'psychology', 'more', 'intelligibility', 'term', 'indications', 'formulae', 'strand', 'blackboard-like', 'agent', 'objects', 'zadeh', 'acquired', 'ensemble', 'evaluate', 'summing', 'formulation', 'direct', 'user-specified', 'traditional', 'songs', 'tuit', 'attain', 'eye', 'relatedness', 'canonical', 'systematically', 'area', 'poster', 'korean-to-japanese', 'adjusting', 'neat', 'kukich', '1979', 'taiwan', 'dimensionality', 'reference', 'warfare', 'tree-bank', 'sentential', 'ucg', 'typically', 'insertion', 'added', 'hpm', 'consequently', 'increase', 'operation', 'sounding', 'sparsity', 'o', 'capabilities', 'sense', 'minimum', 'explores', 'summarise', 'technologies', 'evaluating', 'typed', 'threading', 'meshes', 'end-to-end', 'koskenniemi', '13', 'thus', 'indispensable', 'pcfg', 'equivalents', 'spelling-checking', 'bi-directional', 'morphotactics', 'misunderstandings', 'bear', 'triple', 'modified', 'stands', 'certain', 'time-sensitive', 'circumvent', 'further', 'canadian', 'convolution', 'into', 'permits', 'large-vocabulary', 'anchors', 'vectors', 'articles', 'possible', 'matches', 'depend', 'criterion', 'personnel', '22', 'low-power', 'completed', 'hybrid', 'pharmaceutical', 'interpreted', 'prefix*-stem-suffix*', 'stemming', 'p-cfg', 'distribution', 'being', 'conclude', 'mbr', 'mentioning', 'lexicalised', 'subsequent', 'decfc', 'existence', 'expressed', 'relative', 'reconcile', 'advantages', 'emphatic', 'properly', 'trdr', 'solved', 'two-level', 'back', 'pos-tag', 'tenses', 'valiant', 'technical', 'know', 'pourpre', 'advertisements', 'patent', 'wer', 'unless', 'multi', 'packets', 'view', 'citing', 'generalizing', 'underlying', '32.8', 'independently', 'implications', 'multiparagraph', 'potentially', 'motivators', 'specific', 'name', 'robustly', 'drafts', 'probabilities', 'adapted', 'constituent', 'speed', 'part-of-speech', 'extension', 'person', 'story-telling', 'phonetic', 'cues', 'asymmetric', 'yielding', 'tagging', 'breaking', 'slovak', '2.', 'mwe', 'showed', 'characterizations', 'trec', 'rule-invocation', 'quantities', 'ccrs', '1-2', 'exploits', 'if', 'synthesizes', 'chart-based', 'set', 'm', 'natural', 'improving', 'realizations', 'diagnostic', 'cooccurrence', '2491', '330', 'advocated', 'experience', 'differs', 'treebanks', 'song', 'limited', 'adjectival', 'significance', 'competitive', 'appreciable', 'tcnl', 'quantifier', 'word-trigram', 'hypothesis', 'open', '46.0', 'reasons', 'though', 'avoidance', 'scoping', 'scruffy', 'roughly', 'presuppositions', 'dalrymple', 'pustejovsky', 'assumption', 'fail-soft', 'closed-form', 'sundheim', 'hmm-based', 'compared', 'top-level', 'paraphrased', 'comparing', 'n-ary', 'participated', 'circumstances', 'showing', 'unification', 'structure-directed', 'resolve', 'csr', 'textual', 'rina', 'trend', 'ranks', 'comparisons', 'million', 'levin', 'knowledge-independent', 'edges', 'petrol', 'statistically', 'belief', 'ad', 'involve', 'global', 'representing', 'disjunctions', 'neural', 'unequal', 'at', 'retrieve', 'behavioral', 'asr', 'recognizes', '1', 'whether', 'syntactico-semantic', 'mission', 'inefficient', 'nearly', 'long-term', 'corpus-', '-speaking', 'expectations', 'demonstration', 'checks', 'interpretation', 'ratio', 'upon', 'gaps', 'finally', 'translate', 'style', 'highlighting', 'gazdar', 'others', 'english-to-korean', 'segmentations', 'directionality', 'great', 'constraint-based', 'close', 'program', 'transcripts', '1992', 'formation', 'sable', 'subsets', 'selects', 'verification', 'applied', '23', 'thesaurus', '20k', 'appropriate', 'question-focused', 'boolean', 'mwes', 'using', 'brings', 'toward', 'homogeneous', 'until', 'herein', 'signatures', 'less', 'windows', 'enhanced', 'languages', 'unl-tree+l0', 'combining', 'fails', 'bigrams', 'tutorial', 'nov93', 'ad-hoc', 'sa', 'sight-impaired', 'domain-related', 'cohesion-based', 'its', 'corresponding', 'seem', 'related', '--', 'us', 'superordinate', 'lincoln', 'phrasing', '76.2', 'memo-functions', 'culling', 'month', 'trigram', 'tape-recorded', 'placement', 'exclamation', '50', 'distributions', 'em', 'floppy', 'intra', 'retrieval', 'glue', 'movements', 'external', 'parameter', 'chemical', 'blond', 'bleu', 'calculating', 'senseval', 'strict', 'nec/sheffleld', 'text-understanding', 'width', '20k-word', 'instance', 'weak', 'separate', 'f-measure', 'modules', 'landsbergen', 'descriptions', 'former', 'end-product', '126,610', 'broadly', 'amount', 'published', 'analogies', 'removes', 'explore', 'modifiers', 'missing', 'usual', 'wordnet', 'multi-document', 'explained', '3-character', 'score', 'congruence', 'review', 'involves', 'characters', 'co-occurrence', 'coedition', 'backbone', 'scalable', 'plugs', 'srh', 'assignment', 'percent', 'lower-bound', 'concrete', 'concept', 'correctors', 'antecedence', 'after', 'interacting', 'semantically-derived', 'encyclopedia', 'require', 'top-down', 'picking', 'sensitive', 'reformulation', 'system', 'honorifics', 'describing', 'correcting', 'advances', 'correlate', 'concept-concept', 'autosegmental', 'r', 'cluster', 'city', 'deals', 'rankings', 'vector', 'commonlisp', 'associative', 'japanese', 'collins', 'tree-based', 'extensive', 'automata', 'linking', 'underway', 'internet', 'grounding', 'when', 'embodying', 'length', 'trained', 'dimensions', 'regularity', 'superset', 'markedness', 'fix', 'essays', 'light-hearted', 'grammaticality', 'query', 'explain', 'prototype', 'deep', '49', 'presenter', 'phrase-based', 'constrain', 'work', 'best-path', 'consistent', 'commonsense', 'plateau', 'unified', 'investigation', 'pipeline', 'portability', 'age', 'wright', 'rewriting', 'initial', 'convey', 'substantial', 'svms', '79.1', 'disposition', 'regarding', 'significantly', 'selecting', 'subordinate', 'has', 'as-closed', 'exist', 'solution', 'resolves', 'human-computer', 'certainty', 'capturing', 'instruct', 'co-occurrences', 'positions', 'degrades', 'pointers', 'joint', 'contained', 'np', 'sites', 'here', 'realization', 'declaratively', 'flexp', 'identification', 'priming', 'out', 'ground', 'hierarchy', 'procedures', 'proportion', 'ccr', '99', 'chunking', 'argument', 'leading', 'access', 'context-sensitive', 'conll', 'saturation', 'or', '15-fold', 'content-independent', 'constitute', 'finite-state', 'costs', 'non-linguistic', 'labor', 'deterministic', 'mimics', 'ltag', 'spend', 'down', 'pk-open', 'random', 'densities', 'following', '7.5', 'increasingly', 'granularity', 'pairs', 'digitalization', 'leads', 'considerable', 'determiners', 'flexiable', 'enrollment', 'dominate', 'designed', 'perceptions', 'article', 'harvesting', 'expect', 'domain-independent', 'figures', 'explains', 'intuitive', 'difficult', 'english/japanese', 'guaranteed', 'example', 'dp', 'focussed', 'differ', 'transferred', 'procedural', 'tune', 'attained', 'resnik', 'left', 'wildcards', 'function', 'similarity-driven', 'introducing', 'expressibility', 'mapped', 'piece', 'funding', 'crl', 'subject', 'representational', 'beginning', 'incoherent', 'straight', 'oracle', '98', 'perceptual', 'posts', 'maximum-entropy', 'duration', 'real-time', 'benchmark', 'lexical-functional', 'hierarchies', 'sophisticated', 'pronoun', 'regularities', 'stereotyped', 'increasing', 'invocations', 'left-corner', 'oz', 'facial', 'horn', 'arrive', 'values', 'relied', 'dialogs', 'agents', 'regard', 'superior', 'measured', 'determine', 'feasible', 'swedes', 'cross-lingual', 'respectively', 'lookup', 'gracefully', 'roots', 'schema', 'interchange', 'reasonable', 'sequence', 'slm', 'estimating', 'non-training', 'extracted', 'informing', 'simpler', 'coherent', 'was', 'employing', 'sprint', 'mle', 'exists', 'pre-processing', 'court', 'inflection', 'csg', 'conversation', 'mu', 'mutli-document', 'information-state', 'satisfactorily', 'different', 'porting', 'fielded', 'element', 'conventional', 'reason', 'plausibility', 'accessible', 'referential', 'closest', 'cross-validation', 'konolige', 'generalizable', 'writing', 'careful', 'word-based', 'present', 'speaker', 'affixations', 'permitting', 'contributes', 'toolkit', 'removal', 'standards', 'serves', 'k-means', 'acts', 'roughly.01', 'unproved', 'lexically', 'facilitated', 'recognizer', 'mutually', 'wsj', 'devise', 'english/chinese', 'adopts', 'seen', 'another', 'coherence', 'ntpc', 'probability-based', 'automatically', 'chronological', 'denotes', 'rule', 'generality', 'rareas', 'mechanisms', 'type-unification', 'dilemma', 'suitabledata', 'overcome', 'real-world', 'continuous', 'compares', 'scenes', 'pruned', 'tactical', 'unl-l0', 'connectivity', 'corrective', 'inevitable', 'packed', 'strengths', 'cbmt', 'obtain', 'theorising', 'recognized', '2002', 'bilingual', 'segments', 'oov', 'deliver', 'determining', 'quite', 'dependency-based', '1984', 'compose', 'intex', 'trees', 'multi-page', 'correction', 'sensu', 'sections', 'stated', 'female', 'resource-limited', 'diagram', 'reduce', 'integrates', 'essentially', 'statistic-based', 'topic', 'pragmatics', 'any', 'flexible', 'extensible', 'constructed', 'indicative', 'disambiguated', 'learn', 'correspondence', 'extreme', 'spaniards', 'will', 'implicit', 'side', 'greater', 'rightward', 'answered', 'part-', '45', 'future', 'source-channel', 'correspond', 'customizable', 'delivery', 'so', 'mark-up', 'nist', '100', 'requested', 'requirements', 'transducers', 'specificity', 'graphical', 'an', 'record', 'cubic', '-an', 'attacked', 'phenomena', 'psycholinguistic', 'minimizes', 'collect', 'salesman', 'il', 'parameters', 'variables', 'empirically', 'nlp', 'written', 'concise', 'products', 'lexico-syntactic', 'sex-dependent', 'draws', 'nominal', 'track', 'bidirectional', 'rejects', 'possibility', 'mutual', 'contrast', 'dom', 'np-hard', 'failed', 'memory-based', 'czech-english', 'edit', 'content-bearing', 'might', 'accords', \"'s\", 'units', 'atis', 'laplacian', 'impediment', 'lies', 'incorporate', 'thereby', 'only', 'byron', 'synthesis', 'correctness', 'recorded', 'viterbi', 'academic', 'communicative', 'factoid', 'success', 'valid', 'contains', 'bulgarian', 'wi', 'inc', 'surface', 'flavors', 'under-specified', 'omissions', 'standard', 'however', 'user-directed', 'clue', 'entailment', 'such', 'expected', 'intuition', 'project', 'maxent', 'matter', 'suggest', 'polysemy', 'geared', 'linear-chain', 'connective', 'palmer', 'lack', 'copy', 'changes', 'architectural', 'parse-based', 'free', 'condensation', 'enhancement', 'exploring', 'deictic', 'performance', 'probability', 'rules', 'authors', 'detection', 'independent', 'specifications', 'aligner', 'aiming', 'speed-up', 'feeling', 'complementary', 'finegrained', 'influences', 'depenencies', 'ie', 'limited-domain', 'san', '~0.25', 'claim', 'customized', 'acquire', 'outperforms', 'nthu', 'serial', '84.6', 'advance', 'pertaining', 'journal', 'investigations', 'atns', 'ascribe', 'text', 'quantitative', 'why', 'phonotactic', 'aims', 'speedup', 'recall', 'referenced', 'annotations', 'variants', 'annotators', 'elimination', 'developers', 'illustrative', 'similarity', 'shallow-parsed', 'german-english', 'determines', 'processors', 'understands', 'denoting', '18.6', 'utilizes', 'largely', 'lexicalization', 'visualization', 'disregard', 'relation-based', 'assign', 'composed', 'nomad', 'forecasts', 'density', 'transfer', 'dialogue', 'word-semantic', 'character-based', 'attractive', 'embedded', 'present-day', 'consist', 'reflecting', 'overlapping', 'reproducible', 'activities', 'commands', 'korean-english', 'medium-length', 'logic-based', 'equipped', 'printed', 'building', 'lexical', 'demands', 'determined', 'finely', 'dictionary', 'suppressing', 'traveling', 'mrd', 'databases', 'identifies', '~', 'distinct', 'adjacency', 'chip', 'models', 'investigate', 'lang', 'pooling', 'longer', 'live', 'unify', 'indexings', 'proposing', 'abstraction', 'unconstrained', 'does', 'measures', 'audio', 'factors', 'aggregation', 'prediction', 'with', 'sublanguage', 'anchoror', 'accessing', 'subjects', 'mesh', 'terrorist', 'do', 'recursive', 'additionally', 'asking', 'damaging', 'logon', 'capitalizes', 'meets', 'caused', 'out-degree', 'solve', 'usefully', 'version', 'avoid', 'files', 'were', 'text-level', 'stable', 'templates', 'las', 'judicious', 'attributes', 'machine-readable', 'pints', 'frames', 'lower', 'statements', 'assembles', 'intenslonal', 'strong', 'usrs', 'already', 'displayed', 'configurable', 'control', '37', '14.0', 'forward', 'history-based', 'attribute', 'selection', 'reversible', 'fonts', 'especially', 'substituting', 'having', 'attentional', 'candidate', 'case-based', 'attachment', 'consistency', 'grouping', 'deaf', 'suitably', 'conjunctions', 'and/or', 'tree', 'transliteration/backtransliteration', 'case-frame', 'adjoining', 'observation', 'post', 'al.', 'discussed', 'linguistically', 'morphemes', 'restricted', 'udrss', 'raw', 'implicitly', 'regarded', 'various', 'translators', 'nouns', 'maximum', 'reappraising', 'experiment', 'computed', 'perspective', 'chinese-to-english', 'fair', 'describe', 'variety', 'secondly', 'summac', 'opposed', 'belong', 'functionalities', '2', '160', 'argumental', 'publication', 'embodies', 'far', 'breakdowns', 'naive', 'difficulty', 'useful', 'least', 'nearing', 'plan', 'good', 'projecting', 'unannotated', 'sequential', 'relationships', 'meant', 'ie-enhanced', 'semantic', 'vary', 'speaker-specific', 'furthermore', 'tractable', 'numbers', 'allows', 'lesser', 'insightful', 'spg', 'spanning', 'limitations', 'continuation', 'rejoinder', 'head-to-head', 'construction', 'abandoned', 'intense', 'could', 'illustrated', 'irrelevant', 'ongoing', 'warren', 'rerank', 'expansion', 'marked', 'magnitude', 'compiled', 'understand', 'seems', '20', 'considered', 'worse', 'purposes', 'component', 'coordinates', 'definition', 'always', 'complicated', 'proposition', 'chart-parser', 'material', 'holding', 'fundamental', 'lateral', 'nlp-system', 'obtaining', 'used', 'official', 'compact', 'relies', 'analyze', '4.4', 'slipper', '89.75', 'sense-tagged', 'financial', 'input', 'want', 'islands', 'tool', 'volume', 'threads', 'learner', 'spent', 'bank', 'exceeded', 'carried', 'elastic', 'portion', 'means', 'provably', 'tri-gram', 'definitions', 'towards', 'polynomial', 'leeway', 'highlight', 'detailed', 'guide', 'presented', 'motivated', 'owing', 'response', 'morpa', 'reveals', 'unpleasant', 'increases', 'string', 'common', 'â€“', 'production', 'administrative', 'annotated', 'conferences', 'legal', 'six', '87.5', 'presumed', 'three-tiered', 'implements', 'underpinning', 'challenges', 'strictly', 'remedies', 'aid', 'comes', 'svm', 'proprietary', 'predictive', '1991a', 'obtains', 'unlike', 'verb', 'improvement', 'deterministically', 'non-translators', '400', 'annotation', 'montagovian', 'poorly', 'exploration', 'needs', 'off', 'cohesion', 'indexing', 'emotions', 'characterize', 'dividing', 'new', 'matrices', 'list', 'responding', 'reflects', 'readily', 'contents', 'made', 'job', 'implementations', 'vowel', 'insufficient', 'appears', 'f1', 'linguistics', 'title-driven', 'address', 'unl', 'high-quality', 'hypotheses', 'symbolic', 'theoretic', 'searching', 'informally', 'training', 'dmlp', 'exploiting', 'and', 'clause', 'did', 'result', 'entity', 'contributing', 'fact', 'failure', 'somewhere', 'cascades', 'changing', 'extractive', 'meetings', 'onto', 'mechanical', 'rainform', 'advanced', 'tuning', 'mentioned', 'connecting', 'span', 'fine-grained', 'optical', 'facts', 'phone', 'promotes', 'subpredicates', 'including', 'unrestricted', 'evolution', '1991', 'multilingually', 'discriminative', '2008', 'unmodified', 'expand', 'kl-one-like', 'statistics', 'clauses', 'strategy', 'predictably', 'decade', 'charts', 'deriving', 'dependents', 'substitutability', 'retrieved', 'large-scale', 'developing', 'satisfactory', 'hansards', 'excess', 'unmarked', 'noting', 'german', 'additions', 'controls', 'readers', 'ir', 'eliciting', 'unfortunately', 'ungrammatical', 'optimizes', 'crf', 'international', 'greatly', 'prove', 'available', 'exhaustiveness', 'wishes', 'documents', 'soames', 'skips', 'msr-', 'post-processing', 'reflexive', 'supervised', 'transcribing', 'cder', 'connectionist', 'is', 'criterionsm', 'requiring', 'keyboard', 'structuring', 'combinations', 'word-level', 'phrases', 'read', 'dfa', 'corpus-based', '1982', 'contrasted', 'guis', 'virtue', 'multi-source', 'collection', 'categorial', 'isomorphic', 'hbg', 'summarization', 'established', 'algorithms', 'winter', 'technique', 'thoughts', 'compilation', 'word-to-word', 'multiplication', 'oriented', 'built', 'according', 'narrow', 'simulate', 'planner-based', 'syntactically', 'messages', 'past', 'most', 'triggered', 'favorably', 'interpret', 'decomposition', 'story', 'assist', 'parse-trees', 'network', 'organization', 'fragment-and-compose', 'board', 'programs', 'misspelled', 'top-ranked', 'humans', 'mature', 'fly', 'morphologically', 'original', 'what', 'supported', 'covering', 'assigned', 'running', 'bikel', 'biased', 'media', 'can', 'abduction', 'lexicall', 'laid', 'previously', 'men', '88.2', 'ims', 'emails', 'those', 'characterized', 'hierarchically', 'central', 'fewer', 'prosodic', 'agree', 'parsers', 'demonstrative', 'listeners', 'robustness', 'structure-sharing', '94.3', 'multimedia', 'chunk', 'puts', 'revision', 'phrase', 'kullback-leibler', 'enhancing', 'interruptions', 'co-occur', 'email-threads', 'bayes', 'english-french', 'achieving', 'relevant', 'this', 'cue', 'scientific', 'checker', 'architecture', 'leveraging', 'multi-paragraph', 'face', 'lr', 'hand-crafted', 'conducted', 'follows', 'pereira', 'ungrammatically', 'grade', 'phonetically-based', 'tie', 'proposal', 'dcg', 'misspellings', 'questions', 'utilizing', 'taggers', 'colon', 'carries', 'gesture', 'against', 'effective', 'transcribed', 'catalyze', 'rise', 'transformed', 'english-japanese', 'despite', 'key', 'excluded', 'integrated', 'stage', 'hot', 'adhere', 'punctuation', 'axis', 'morphosyntactic', 'supporting', 'among', 'every', 'enlargement', 'eventually', 'tests', 'lemma-based', 'foresee', 'nodes', 'grosz-sidner-style', 'translates', 'ilimp', 'strength', 'elaborate', 'programming', 'corporation', 'materials', 'justify', 'telephone', 'framed', 'avoiding', 'expletive', 'limsi', 'skill', 'module', 'reading', 'moderately', 'realized', 'placing', 'estimated', 'operating', 'generates', 'protein', 'wsd', 'restarting', 'unidentified', 'probable', 'proposes', 'restrict', 'disambigation', 'events', 'parsetalk', 'eu', 'briefly', 'lemma', 'simplicity', 'first-order', 'targeted', 'bag-of-words', 'mismatches', 'registration', '60.62', 'middle', 'frequency', 'pylonic', 'verify', 'degree', 'approximation', 'realize', 'sentence-aligned', 'asl', 'typing-algorithm', 'interested', 'concerned', 'fields', 'basing', 'usr', 'precision', 'recover', 'lattice-based', 'via', 'yield', 'controlled', 'test', 'concatenation', 'cognitively', 'defends', 'wikipedia', 'formulated', 'cross-linguistically', 'tendency', 'mu-project', 'obvious', 'reconciled', 'browsing', 'combinatory', 'environments', 'typing', 'voting-', 'path', 'interpolate', 'increased', 'class', 'ltfor', 'priorities', 'backwards', 'biomedical', 'formatfed', 'construction-specific', 'forming', 'goal', 'jiang', 'many-paths', 'source-language', 'logistics', 'adaptation', 'bracket', 'stages', 'polarization', 'clarification', 'wordform', 'reduced', 'mainly', 'corroborate', 'wider', 'unlikely', 'architectures', 'attendance', 'crucial', 'too', 'majority', 'there', 'newspaper', 'yet', 'simplify', 'synonymy', '96', 'pool', 'identical', 'handcrafted', 'phonograms', 'sun', 'outputting', 'specifies', 'monitoring', 'thesis', 'f-measures', 'character-', 'moves', 'well-written', 'italian', 'processed', 'i', 'bind', '1989', 'evidences', 'permitted', 'vice-versa', 'dp-based', 'correct', 'unstable', 'nominals', 'hospital', 'biasing', 'deduced', 'speakers', 'important', 'simply', 'insights', '[', 'combine', 'likely', 'discuss', 'applicability', 'basically', 'patient', 'fsm', 'ellipsis', 'created', 'shift-reduce', 'knows', 'chance', 'formal', 'predicate-argument', 'substrate', 'images', 'draft', 'concept-distance', 'biological', '6.5', 'brought', 'friedman', 'notation', 'specifying', 'realistic', 'deduction', 'nec', 'almost', 'shallow', 'ace', 'idiosyncrasies', 'encyclopedias', 'reichenbachian', 'propositional', 'case', 'earlier', 'national', 'easy', 'schematic', 'hidden-variable', 'multi-level', 'conversational', 'constructing', 'comprehension', 'choose', 'mediate', 'write', 'computes', 'required', 'acquiring', 'deductive', 'special', 'ftrd', 'evolved', 'restoration', 'verbal', 'illuminating', 'recognizing', 'objective', 'grown', 'should', 'priors', 'augmenting', 'stresses', 'polish', 'inescapable', 'tacitus', 'over-fitting', 'phone-string', 'interest', 'graphic', 'zernik87', 'poor', 'inferential', 'associate', 'extremely', 'relational', 'predictions', 'investigated', 'event-based', 'ofthe', 'defines', 'type', 'deviations', 'observed', 'bottleneck', 'methodologies', 'hypertext', 'montague', 'associations', 'check', 'gold', 'basis', '&', 'excellent', 'prospect', 'neglected', 'learners', 'xml-based', 'blog', 'improved', 'scenic', 'templated', 'readable', 'distributed', 'described', 'effort', 'full', 'slow', 'n-fold', 'dataset', 'q/a', 'projections', 'compensation', 'make', 'while', 'assume', 'each', '1993', 'lambek', 'in-domain', 'de', 'smadja,1993', 'negligible', 'low-cost', 'i.e.', 'closes', 'reflect', 'classifies', 'slavic', 'stereotypic', 'appear', 'sometimes', 'create', 'researchers', 'concept-to-speech', 'cross-entropy', 'services', 'foundered', 'adverbs', 'time', 'performances', 'tv', 'sequentially', 'hlt', 'mandarin', 'depth', 'constraint', 'assigning', 'predict', 'syntax', 'essential', 'lyrics', 'times', 'unnecessary', 'pass', 'feedback', 'vs.', 'avoids', 'digital', 'namely', 'genre-specific', 'edge', 'organizing', 'interactively', 'speeding', 'instead', 'thematic', 'forms', 'circuit', 'metric', 'natural-language', 'rule-based', 'arcs', 'wide-coverage', 'associated', 'platforms', 'watch', '8', 'aggregates', 'argued', 'manual', 'event', 'whole', 'su', 'not', 'detecting', 'victims', 'sent', 'hong', 'retaining', 'detail', 'synthesizing', 'al', 'care', 'speech', 'segmental', 'lfg', 'speak', 'fourteen', 'successfully', 'additional', 'expectation', 'resources', 'inference', 'questioning', 'isolate', 'temporal', 'clausal', 'systems', 'arbiter-based', 'antworth', 'revealed', 'spots', 'perhaps', '120k', 'dash', 'nature', 'fall', 'existing', 'use', 'small', 'primarily', 'together', 'wall', 'much-studied', 'mistakes', 'seven', 'accuracy', 'concepts', 'addressee', 'placed', 'parametrized', 'basque', 'assessed', 'bit-vector-based', 'lexicalized-grammar', 'characters-based', '1.5', 'fillers', 'news', 'teaching', 'conglomeration', 'bit', 'candidates', 'decisions', 'indexed', 'difficulties', 'causal', 'giving', 'linguistic', 'done', 'topic-sensitive', 'words', 'statement', 'like', 'exemplify', 'status', 'understood', 'medicine', 'providing', 'confirm', 'planner', 'face-to-face', 'analysing', 'explanations', 'roles', 'poses', 'kruse-man', 'negations', 'automate', 'display', 'debate', 'adding', 'concern', 'overheads', 'differently', 'false', 'elaborating', 'restrictions', 'conversion', 'beijing', 'believed', 'second-order', 'competing', 'redundancy', 'directly', 'horizons', 'rarely', 'incrementally', 'parser', 'discussing', 'inferences', 'locating', 'exhaustive', 'mappings', 'tested', 'macro-average', 'kernel', 'reconstructing', 'approach', 'basic', 'noisy', 'demonstrate', 'algebra', 'converges', 'roget', 'high', 'parc', 'genres', 'kind', 'underline', 'map', '5', 'seeded', 'distinctive', 'levels', 'severely', 'part', 'scripts', '8000-word', 'interplay', 'focuses', 'restriction', 'derivational', 'utility', 'repeating', 'partial-parsing', 'phonological', 'variation', 'filtered', 'ideas', 'concentrated', 'english', 'reduction', 'prc', 'distinguish', 'asked', 'scf', 'protocol', 'modular', 'outline', 'york', 'occurring', 'commas', 'iterative', 'hub', 'simultaneously', 'warrant', 'entirely', 'noted', 'language', 'behaviors', 'for', 'maintaining', 'perspicuously', 'both', '=', 'initiatives', 'domain', 'channel', 'remote', 'as-open', 'convenient', 'word-segmented', 'ctl', 'underspecified', 'social', 'groupings', 'hours', 'semi-automatic', 'non-literal', 'choices', 'ccling', 'sequences', 'enumerating', 'multi-tagging', 'task-specific', 'weakness', 'service', 'alone', 'demonstrates', 'answer', 'dimensionalized', 'protein-protein', 'smaller', 'proof', 'look', 'appealing', 'conditions', 'referencing*', 'inflective', 'classification-based', 'investigates', 'question', 'centering', 'formalisms', 'formalism', 'non-np-antecedents', 'ability', 'arose', 'filled', 'processor', 'undisambiguated', 'semiphone', 'february', 'theories', 'temporary', 'heart', 'goal-directed', 'level', 'fully', 'desired', 'taxonomic', 'directions', 'larger', 'networks', 'expressions', 'quantifying', 'very', 'achieve', 'identities', 'requires', '4gb', '86.9', 'grammatically', 'off-line', 'tutor', 'sign', 'predicates', 'indices', 'it', 'tectogrammatical', 'multi-pathway', 'that', 'comma', 'encodes', '1990', 'recent', 'habituality', 'paul', 'french', 'classifying', 'initially', 're-usable', 'now', 'ms-l0', 'rcg', ']', 'linux', 'stems', '6.3', 'interpolation', 'concludes', 'users', 'randomized', 'discussions', 'accounts', 'spectral', '400gb', 'working', 'southern', 'describable', 'tailoring', 'likewise', 'information', 'signal', 'process', 'feature-based', 'express', 'minimal', 'before', 'lemmas', 'plans', 'mil', 'prior', 'syntax-based', 'mps', 'opinion', 'multiplicative', 'redundant', 'unstemmed', 'deconverter', 'house', 'tables', 'dags', 'produces', 'pagerank', 'fundamentally', 'automated', 'things', 'cas', 'dictionaries', '32', 'classify', 'edr', 'eventual', 'literature', 'phases', 'ch', 'lcs-marine', '42', 'permit', 'carnegie-mellon', 'attributable', 'aspects', 'attempting', 'razor', 'conveyed', 'enrichment', 'scored', 'richer', 'other', 'depending', 'true', 'integration', 'command', 'topic-bearing', 'elicited', 'environment', 'morpheme', 'effect', 'phase', 'reality', 'presentations', 'lnr', 'enable', 'shifting', 'calculus', 'intersentential', 'appropriately', 'rapid', 'lead', 'comparable', 'introduction', 'phonology', 's-vsm', 'method', 'diego', 'instances', 'grs', 'terminal', 'investigating', 'appropriator', 'polarized', 'paradigms', 'exhaustively', 'd', 'affects', 'scfs', 'quadratic', 'maximally', 'island', 'evaluations', 'mark', 'hard', 'imp', 'manner', 'treats', 'dops', 'compete', 'web', 'translation', '28,449', 'bootstrapping', 'otp', 'kpsg', 'living', 'argue', 'node-based', 'effectively', 'sufficient', 'concordancer', 'seeds', 'tracking', 'planning-based', 'labeled', 'wordbreaks', 'section', 'presupposition', 'preceding', 'kokugojiten', 'chine', 'compositional', 'single', 'extracting', 'oleada', 'everyday', 'cepstrum-based', 'generated', 'these', 'introspection', 'summary', 'certification', 'ngrams', 'creation', 'intensive', 'represented', 'word-aligned', 'extended', 'cdhmm', 'optimisation', 'importance', 'departure', 'webcasting', 'travel', 'extraction', 'wizard', 'stark', 'getting', 'subcategorization', 'phrase-structure', 'comparative', 'different-quality', 'begin', 'speaker-independent', 'syntlex', 'main', 'order-sensitive', 'grammars', 'intra-sentential', 'pruning', 'minimize', 'token-based', 'develop', 'shall', 'dhpl', 'otin', 'extracts', 'theory', 'scope', 'represents', 'reducing', 'lr-parsers', 'calibrating', 'select', 'orders', 'chat-80', 'october', 'path-based', 'emoticons', 'profile', 'incomplete', 'sl', 'template-based', 'essay', 'implement', 'grouped', 'complete', 'task', 'accumulated', 'segmented', 'optimality', 'considers', 'image', 'interface', 'paramax', 'avenue', '22-38', 'g', 'usefulness', 'personal', 'ngram', 'by', 'speech-based', 'contiguity', 'complex', 'computing', 'cohesive', 'vehicle', '2006', 'would', 'engines', 'trainable', 'tags', 'multilingual', 'under', 'transformation', 'recognition-time', 'see', 'adhoc', 'discovered', 'helpful', 'ferret', 'expensive', 'transcriptions', 'single-strategy', 'because', 'issues', '54.55', 'collocation', 'bases', 'possess', 'annotate', 'unnatural', 'treated', 'filtering', 'gave', 'perspective-taking', 'kong', 'interprets', 'structural', 'root', 'thorough', 'they', 'minor', 'symbol', 'supplement', 'grid', 'exceeds', 'adapt', 'proficiency', 'tree-adjoining', 'enables', 'complexity', 'fits', 'excludes', 'anaphora', 'smoothing', 'computationally', 'move-tagged', 'piped', 'successively', 'zero', '97', 'devised', 'encountered', 'conjuncts', 'agreement', '1995', 'lcs', 'class-dependent', 'bigger', 'functions', 'virtual', 'marine', 'based', '87.2', 'cclinc', 'prevails', 'muc-3', 'exploitation', 'simplest', 'understanding', 'conjunction', 'visualized', 'insight', 'occurs', 'second', 'harmful', 'intel', 'linde', 'frame', '97.24', 'report', 'online', 'participants', 'vsm', 'newspapers', 'analyzed', 'children', 'fast', 'introduces', 'beyond', 'toolkits', 'ordata', 'antonymous', 'failures', 'eca', 'broadcast', 'discovering', '1998', 'tends', 'university', 'exotic', 'rooted', 'reordering', 'thing', 'videodisc', 'counterexamples', 'collocations', 'froff', 'rm', 'voice', 'drt', 'illustrate', 'properties', 'word-clustering', 'pdtb', 'fully-connected', 'attention', 'surprising', 'includes', 'incremental', 'interval', 'extends', 'reflexives', 'applies', 'be', 'them', 'handling', 'searched', 'structures', '2-character', 'boundaries', 'channeling', \"'flat\", 'coordinations', 'first', 'accept', 'spelling-checkers', 'non-overlapping', 'sum', 'regardless', 'best-reported', 'promising', 'english-chinese', 'denotational', 'equivalences', '500,000', 'converge', 'deviates', 'hdag', 'voting', 'segmentation', 'text-to-speech', 'non-lr', 'presentor', 'augment', 'consideration', 'styles', 'eurowordnet', 'memos', 'chart-parsing', 'operators', '80.5', 'light', '1999', 'decoder', '1974', 'pronominalization', 'graceful', 'incorporating', 'clearly', 'inflected', 'dramatically', 'pragmatic', 'define', 'support', 'modern', 'casting', 'counterpart', 'message-passing', 'testing', 'lemmatized', 'converted', 'making', 'cross-platform', 'idea', 'tend', 'quantifiers', 'ambiguities', 'detected', 'randomly', 'automaton', 'sentence-level', 'meeting', 'grolier', 'intentional', 'kernels', 'predicts', 'goals', 'consecutive', 'his', '96.6', 'advocacy', 'reproduce', 'captured', 'comparison', 'of', 'gains', 'forward-backward', 'judgement', 'solving', 'strategies', 'viable', '2.5', 'replete', 'shared', 'small-sized', 'numerical', 'selected', 'high-performance', 'remarks', 'uniformly', 'mono-lingually', 'posteriori', 'xerox', 'application', 'allow', 'nothing', 'relying', 'bulk', 'adopt', 'play', 'usually', 'labeling', 'dynamically', 'serious', 'chunker', 'capable', 'ensembles', 'three-way', 'complicates', 'inferred', 'abstract', 'glosser', 'fitting', 'gjw86', 'reject', '1978', 'simultaneous', 'time-synchronous', 'conceptual', 'switchboard', '71.0', 'group', 'satisfied', 'nitpick', 'applications', 'profiles', 'helps', 'held', 'divided', 'discourses', 'seven-year', 'human-ranked', 'ocr', '94.1', 'planners', 'on-line', \"'glue\", 'communicator', 'military', 'language-independent', 'semantics', 'i.e', 'regular', 'dumber', 'bottom', 'call', 'imperative', 'management', 'task-based', 'produce', 'mismatch', 'years', 'dramatic', 'subtrees', 'learned', 'computer-based', 'reiteration', 'compute', 'summac-1', 'acyclic', 'japanese-english', 'treelet', 'macro-planning', '/', 'weight', 'lt', 'methodology', 'remaining', 'much', 'who', '66', '24', '0.456', 'equally', 'ne', 'developed', 'cfg', 'hand', 'dictation', 'etc..', 'scores', 'ranking', 'sound', 'yields', 'co-ordinated', 'basics', 'numbering', 'linguists', 'costly', 'conversations', 'pronominal', 'attempt', 'javelin', 'problems', 'chinese', 'provided', 'final', 'introduced', 'preference', 'universal', 'answering', 'non-deterministic', 'local', 'discrimination', 'trains', 'validate', 'formulas', 'europarl', 'accomplishments', 'conforms', 'np-complete', 'discusses', 'tasks', 'alphabets', 'head-driven', 'e.g', 'mt', 'varied', 'cross-domain', 'intentions', 'iii', 'operational', 'preponderantly', 'multi-path', 'ge', 'clear', 'presentation', 'understanders', 'essay-based', 'storage', 'examine', 'informal', 'blogs', 'madcow', '10.08', 'property', 'cmu', 'weights', 'unsegmented', 'adjectives', 'trends', 'laughed', 'active', 'format', 'range', 'substrings', 'include', 'editor', '9000', 'keywords', 'confines', 'gazetteer', 'pretty', 'bearing', 'treebank', 'originally', 'conditional', 'producing', 'expert', 'workers', 'apartment', 'graph-based', 'currently', 'incorporated', 'stochastic', 're-ordering', 'noone', 'eliminates', 'ourselves', 'one-time', 'pc-kimmo', 'proven', 'server', 'task-oriented', 'customization', 'just', 'recovery', 'longest', 'directing', 'highest', 'semantic-oriented', 'completeness', 'dominating', 'experiences', 'expressing', 'own', '109', 'non', 'real-word', 'obtainable', 'looks', 'deviant', 'extending', 'difference', 'proper', 'two-phase', '?', 'areas', 'arpa', 'developments', 'general', 'conform', 'semicolon', 'discovery', 'half', 'augmented', 'similar', 'possibilities', 'scale', 'collected', 'divide', 'identity-of-relations', 'requirement', 'whatever', 'edited', '35.0', 'simplifications', 'agglutinative', 'indicates', 'kit', 'lexically-based', 'themselves', 'wordspotter', 'tag', 'contribution', 'efforts', 'computer-assisted', 'computer', 'pieces', 'rule-reduction', 'same', 'reconstruction', 'genre', 'lexicologists', 'number', 'order', 'entries', 'vocabularies', '0.4023', 'forest-based', 'utterances', 'formalized', 'captions', 'studied', 'choosing', 'unification-based', 'returning', 'through', 'viz', 'lexica', 'ccg', 'anatomy', 'disambiguating', 'atn', 'analogy', 'f-score', 'interdisciplinary', 'experts', 'unlexicalized', 'relations', 'leverages', 'along', \"'tolerant\", 'repeatedly', 'establishes', 'non-english', 'noisy-channel', 'public', 'corefer', 'some', 'multidimensional', 'executed', 'community', 'segment', 'non-terms', 'extractor', 'semi-supervised', 'pushdown', 'proceeds', 'sttk', 'multi-component', 'contain', 'discourse', 'queries', 'preliminary', 'graph2tree', 'gets', 'unable', 'begin/after', 'disambiguation', 'accurate', 'reduplications', 'crossed', 'illustrates', 'than', 'intractability', 'n-gram', 'open-ended', 'factor', 'latent', 'across', 'feature', 'compactly', 'negative', 'ucgs', 'text-image', 'recordings', 'black-box', 'intended', 'modelling', 'during', 'conclusions', '2000', 'terms', 'i.', 'refined', 'coarse-grained', 'head', 'geometric', 'safe', 'aligning', 'performing', 'posing', 'impact', 'discursive', 'proceed', 'maintains', 'concordances', 'keep', 'ebmt', 'representation', '35', 'acquisition', 'enabling', 'although', 'field', 'resolution', 'situations', 'one', 'retrieving', 'shown', 'classifier', 'c', 'notion', 'boundary', 'interacts', 'speaking', 'sstc', 'designs', 'memorisation', 'm3-e/3', 'relevance', 'whereas', 'p.', 'itself', 'synonym', 'distinction', 'favor', 'token', 'minutes', 'attaining', 'states', 'mileage', 'modifications', 'in', 'lattice', 'exploratory', 'word-sense', 'location', 'muc-7', 'pair', 'genetic', 'sketch', 'constituents', '3d', 'suffer', 'dealing', 'possibly', 'mercer', 'multiple', 'series', 'occam', '73.1', 'ontological', 'inevitably', 'efficiency', 'paper', 'classifiers', 'electronic', 'bare', 'commonly', 'sri', 'word-senses', 'outward', 'articulation', 'delays', 'engineering', 'cyclic', 'variant', 'pcfg-la', 'hope', 'mt-based', 'parsing', 'believe', 'inductive', 'ogden', 'usage', 'knowledge', 'probing', 'efficacy', 'polysemous', 'determination', 'redefine', 'sample', 'designers', 'intersections', 'sublanguages', 'identified', 'saudi', 'unseen', '~1.25', 'persistent', 'user', 'evaluation', 'raised', 'formalising', 'employs', 'discussion', 'creates', 'repository', 'induction', 'performed', 'where', 'nagao,1993', 'responses', 'resource-frugal', 'handles', 'sheffield', 'drawn', 'subjective', 'numeric-valued', 'intriguing', 'study', 'layer', 'open-domain', 'bridging', 'machine-learning', 'intend', 'question/answer', 'code', 'quantified', 'grounded', 'methods', 'accurately', 'survey', 'hands-on', 'the', 'micro-planning', 'enhance', 'aretz', 'scheduling', 'sun4', '86.6', 'biases', 'suitable', 'experimental', 'assembling', 'idf-weighted', 'helping', 'strings', 'character', 'si-nets', 'automating', 'non-parallel', 'must', 'confirmed', 'easier', 'netl', 'pilot', 'categorizing', 'directional', 'library', 'target', 'hierarchical', 'disambiguate', 'salience', 'systemic', 'heuristically-produced', 'kumar', 'repositories', 'displays', 'predicting', 'talking']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4946"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove, dublicated words and punctuation\n",
    "#stop_words = set(stopwords.words('english')) \n",
    "punctuation = ['.', ',', '//', ':', ';', ')', '(', '%', '-']\n",
    "#filtered_txt = [w for w in tokens if not w in stop_words]  \n",
    "filtered_txt = [] \n",
    "\n",
    "#for w in tokens: \n",
    "#    if w not in stop_words and w not in punctuation: \n",
    "#        filtered_txt.append(w)\n",
    "  \n",
    "for w in tokens: \n",
    "    if w not in punctuation: \n",
    "        filtered_txt.append(w.lower())\n",
    "\n",
    "#remove dublicates\n",
    "filtered_tokens = list(set(filtered_txt))        \n",
    "#print(filtered_tokens)\n",
    "len(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pre-processing our corpus consists of 4946 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write vocabulary into a csv file\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    for item in filtered_tokens:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4946"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert tokens of the vocabulary into a dataframe.\n",
    "df_vocabulary = pd.DataFrame(filtered_tokens)\n",
    "df_vocabulary.columns = ['Word']\n",
    "#print(df_vocabulary)\n",
    "df_vocabulary.head(5)\n",
    "len(df_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fetching Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Global vectors and store them in the embeddings_dict \n",
    "embeddings_dict = {}\n",
    "f=open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Word</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>[0.04656, 0.21318, -0.0074364, -0.45854, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>[-0.25539, -0.25723, 0.13169, -0.042688, 0.218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>[-0.12559, 0.01363, 0.10306, -0.10123, 0.09812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "      <td>[-0.076947, -0.021211, 0.21271, -0.72232, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>[-0.25756, -0.057132, -0.6719, -0.38082, -0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Word                                             Vector\n",
       "0   0  the  [0.04656, 0.21318, -0.0074364, -0.45854, -0.03...\n",
       "1   1    ,  [-0.25539, -0.25723, 0.13169, -0.042688, 0.218...\n",
       "2   2    .  [-0.12559, 0.01363, 0.10306, -0.10123, 0.09812...\n",
       "3   3   of  [-0.076947, -0.021211, 0.21271, -0.72232, -0.1...\n",
       "4   4   to  [-0.25756, -0.057132, -0.6719, -0.38082, -0.36..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert dictionary into a DataFrame\n",
    "#put an id for each word\n",
    "embeddings_df = pd.DataFrame(list(embeddings_dict.items()), columns=['Word', 'Vector'])\n",
    "term_id = range(len(embeddings_dict))\n",
    "embeddings_df.insert(0, \"Id\", term_id, True) \n",
    "embeddings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4297"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get glove word embeddings for the words in our vocabulary. \n",
    "# constract a dictionary which contains words in our vocabulary and their respective embedding from GloVe. \n",
    "vocab_dictionary = {}\n",
    "vocab_words = []\n",
    "test_words = []\n",
    "vector_embeddings = []\n",
    "for i in range (len(df_vocabulary)):\n",
    "    if df_vocabulary['Word'][i] in embeddings_dict:\n",
    "        vocab_words.append(df_vocabulary['Word'][i])\n",
    "        vector_embeddings.append(embeddings_dict[df_vocabulary['Word'][i]])\n",
    "\n",
    "#print(vocab_words)\n",
    "#print(vector_embeddings)\n",
    "len(vocab_words)\n",
    "#type(vector_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Embedding Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>but</td>\n",
       "      <td>[-0.0093601, 0.22789, -0.10275, 0.0010893, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apt</td>\n",
       "      <td>[-0.41618, -0.37872, 0.4119, 0.015433, 0.62914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reported</td>\n",
       "      <td>[-0.21093, 0.51757, 0.042662, 0.013656, -0.577...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>groups</td>\n",
       "      <td>[-0.12724, 0.27224, -0.055019, -0.0030393, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slavonic</td>\n",
       "      <td>[-0.39907, -0.76034, -0.17752, 0.22556, -0.110...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word                                   Embedding Vector\n",
       "0       but  [-0.0093601, 0.22789, -0.10275, 0.0010893, 0.2...\n",
       "1       apt  [-0.41618, -0.37872, 0.4119, 0.015433, 0.62914...\n",
       "2  reported  [-0.21093, 0.51757, 0.042662, 0.013656, -0.577...\n",
       "3    groups  [-0.12724, 0.27224, -0.055019, -0.0030393, -0....\n",
       "4  slavonic  [-0.39907, -0.76034, -0.17752, 0.22556, -0.110..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4297"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_id = range(len(df_vocabulary))\n",
    "word_vector_final= pd.DataFrame({'Word': vocab_words, 'Embedding Vector': vector_embeddings})     \n",
    "word_vector_final.index = range(len(word_vector_final)) \n",
    "display(word_vector_final.head(5))\n",
    "len(word_vector_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4297"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the words in your vocabulary file with the ID and embeddings from glove. \n",
    "#get word embedding of the words in the vocabulary by simply joininig the dataframes on word \n",
    "vocabulary = pd.merge(df_vocabulary, embeddings_df, on='Word')\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocabulary['Vector'][0]\n",
    "len(vocabulary['Vector'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the tokens in the corpus we have 4297 for which we have found an embedding from global vectos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Word</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>but</td>\n",
       "      <td>[-0.0093601, 0.22789, -0.10275, 0.0010893, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19219</td>\n",
       "      <td>apt</td>\n",
       "      <td>[-0.41618, -0.37872, 0.4119, 0.015433, 0.62914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293</td>\n",
       "      <td>reported</td>\n",
       "      <td>[-0.21093, 0.51757, 0.042662, 0.013656, -0.577...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>groups</td>\n",
       "      <td>[-0.12724, 0.27224, -0.055019, -0.0030393, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48913</td>\n",
       "      <td>slavonic</td>\n",
       "      <td>[-0.39907, -0.76034, -0.17752, 0.22556, -0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7070</td>\n",
       "      <td>marcus</td>\n",
       "      <td>[0.52047, -0.44494, -0.2596, -0.14926, 0.53999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45209</td>\n",
       "      <td>clustering</td>\n",
       "      <td>[-0.49152, 0.83904, 0.48919, -0.53234, -0.0898...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79856</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>[-0.54975, 0.13891, 0.58945, -0.24693, 0.30243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4640</td>\n",
       "      <td>valuable</td>\n",
       "      <td>[0.34956, 0.24624, 0.20949, -0.15911, 0.3061, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4968</td>\n",
       "      <td>preferred</td>\n",
       "      <td>[-0.20157, 0.31404, 0.42666, -0.17512, 0.39641...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        Word                                             Vector\n",
       "0     34         but  [-0.0093601, 0.22789, -0.10275, 0.0010893, 0.2...\n",
       "1  19219         apt  [-0.41618, -0.37872, 0.4119, 0.015433, 0.62914...\n",
       "2    293    reported  [-0.21093, 0.51757, 0.042662, 0.013656, -0.577...\n",
       "3    503      groups  [-0.12724, 0.27224, -0.055019, -0.0030393, -0....\n",
       "4  48913    slavonic  [-0.39907, -0.76034, -0.17752, 0.22556, -0.110...\n",
       "5   7070      marcus  [0.52047, -0.44494, -0.2596, -0.14926, 0.53999...\n",
       "6  45209  clustering  [-0.49152, 0.83904, 0.48919, -0.53234, -0.0898...\n",
       "7  79856   bootstrap  [-0.54975, 0.13891, 0.58945, -0.24693, 0.30243...\n",
       "8   4640    valuable  [0.34956, 0.24624, 0.20949, -0.15911, 0.3061, ...\n",
       "9   4968   preferred  [-0.20157, 0.31404, 0.42666, -0.17512, 0.39641..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocabulary = vocabulary[['Id','Word', 'Vector']]\n",
    "display(vocabulary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the vocabulary together with word emeddings for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "vocabulary.to_pickle(\"GloVe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19219</td>\n",
       "      <td>apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293</td>\n",
       "      <td>reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48913</td>\n",
       "      <td>slavonic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id      Word\n",
       "0     34       but\n",
       "1  19219       apt\n",
       "2    293  reported\n",
       "3    503    groups\n",
       "4  48913  slavonic"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = vocabulary.drop(columns=['Vector'])\n",
    "display(vocab.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store vocabulary into a csv\n",
    "vocab.to_csv('vocab.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
